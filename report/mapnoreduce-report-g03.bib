Automatically generated by Mendeley Desktop 1.13.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@misc{FrancescoSalbaroli2008,
author = {Salbaroli, Francesco},
file = {:Users/jp/Documents/Mendeley Desktop/Salbaroli/Unknown/Salbaroli - 2008 - Enhancing the Hadoop MapReduce framework by adding fault.ppt:ppt},
institution = {IBM Innovation Centre},
title = {{Enhancing the Hadoop MapReduce framework by adding fault}},
url = {https://issues.apache.org/jira/secure/attachment/ 12393292/FaultTolerantHadoop.pdf},
year = {2008}
}
@article{Bhandarkar2010,
author = {Bhandarkar, Milind},
doi = {10.1109/IPDPS.2010.5470377},
isbn = {978-1-4244-6442-5},
journal = {2010 IEEE International Symposium on Parallel \& Distributed Processing (IPDPS)},
pages = {1},
publisher = {Ieee},
title = {{MapReduce programming with apache Hadoop}},
year = {2010}
}
@book{Kimball2013,
author = {Kimball, Ralph and Ross, M},
file = {:Users/jp/Documents/Mendeley Desktop/Kimball, Ross/Unknown/Kimball, Ross - 2013 - The Data Warehouse Toolkit the Definitive Guide to Dimensional Modeling.pdf:pdf},
isbn = {9781118530801},
publisher = {John Wiley \& Sons, Inc.},
title = {{The Data Warehouse Toolkit: the Definitive Guide to Dimensional Modeling}},
year = {2013}
}
@article{Informaticos2012a,
author = {Inform\'{a}ticos, Sistemas and Software, E Ingenier\'{\i}a D E},
file = {:Users/jp/Documents/Mendeley Desktop/Inform\'{a}ticos, Software/Unknown/Inform\'{a}ticos, Software - 2012 - Facultad de Inform\'{a}tica StreamCloud An Elastic Parallel-Distributed Stream Processing Engine.pdf:pdf},
keywords = {facultad de inform\'{a}tica,inform\'{a}ticos e ingenier\'{\i}a de,software,universidad polit\'{e}cnica de madrid},
number = {December},
title = {{Facultad de Inform\'{a}tica StreamCloud : An Elastic Parallel-Distributed Stream Processing Engine}},
year = {2012}
}
@article{Kalavri2013,
abstract = {MapReduce has recently gained great popularity as a programming model for processing and analyzing massive data sets and is extensively used by academia and industry. Several implementations of the MapReduce model have emerged, the Apache Hadoop framework being the most widely adopted. Hadoop offers various utilities, such as a distributed file system, job scheduling and resource management capabilities and a Java API for writing applications. Hadoop's success has intrigued research interest and has led to various modifications and extensions to the framework. Implemented optimizations include performance improvements, programming model extensions, tuning automation and usability enhancements. In this paper, we discuss the current state of the Hadoop framework and its identified limitations. We present, compare and classify Hadoop/MapReduce variations, identify trends, open issues and possible future directions.},
author = {Kalavri, Vasiliki and Vlassov, Vladimir},
doi = {10.1109/TrustCom.2013.126},
file = {:Users/jp/Documents/Mendeley Desktop/Kalavri, Vlassov/Proceedings - 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2013/Kalavri, Vlassov - 2013 - MapReduce Limitations, optimizations and open issues.pdf:pdf},
isbn = {9780769550220},
journal = {Proceedings - 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2013},
keywords = {Big Data,MapReduce,Survey},
pages = {1031--1038},
title = {{MapReduce: Limitations, optimizations and open issues}},
year = {2013}
}
@article{Dean2008,
abstract = {MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
archivePrefix = {arXiv},
arxivId = {10.1.1.163.5292},
author = {Dean, Jeffrey and Ghemawat, Sanjay},
eprint = {10.1.1.163.5292},
institution = {Google, Inc.},
journal = {Communications of the ACM},
number = {1},
pages = {1--13},
pmid = {11687618},
publisher = {ACM},
series = {SIGMOD '07},
title = {{MapReduce : Simplified Data Processing on Large Clusters}},
url = {http://portal.acm.org/citation.cfm?id=1327492},
volume = {51},
year = {2008}
}
@article{Stewart2011,
author = {Stewart, Robert J and Trinder, Phil W and Loidl, Hans-wolfgang},
number = {Section 6},
pages = {58--72},
title = {{Comparing High Level MapReduce Query Languages}},
year = {2011}
}
@article{La,
author = {La, Strahinja},
file = {:Users/jp/Documents/Mendeley Desktop/La/Unknown/La - Unknown - Providing fault tolerance and scalability of the MapReduce JobTracker using the Infinispan platform.pdf:pdf},
keywords = {-fault tolerance,distributed execution,infinis-,jobtracker,pan,replication,scalability},
title = {{Providing fault tolerance and scalability of the MapReduce JobTracker using the Infinispan platform}}
}
